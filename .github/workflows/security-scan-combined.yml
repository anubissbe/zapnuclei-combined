name: Security Scan (ZAP + Nuclei)

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:

permissions:
  contents: read
  security-events: write

jobs:
  build-and-scan:
    name: Build and Security Scan
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      # Build and start the application
      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '24'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Start application in background
        run: npm start &
        env:
          PORT: 3000

      - name: Wait for application to be ready
        run: |
          echo "Waiting for application to start..."
          timeout 60 bash -c 'until curl -sf http://localhost:3000/health > /dev/null 2>&1; do sleep 2; done'
          echo "Application is ready!"

      - name: Get runner IP for Docker access
        id: ip
        run: echo "address=$(hostname -I | awk '{print $1}')" >> $GITHUB_OUTPUT

      # ZAP Scan - outputs SARIF format
      - name: ZAP Baseline Scan
        uses: zaproxy/action-baseline@v0.15.0
        with:
          target: 'http://${{ steps.ip.outputs.address }}:3000'
          cmd_options: '-a'
          fail_action: false
          allow_issue_writing: false
        continue-on-error: true

      # Convert ZAP JSON to SARIF if needed
      - name: Check ZAP outputs
        run: |
          echo "=== Checking for ZAP output files ==="
          ls -la *.json *.sarif *.html *.md 2>/dev/null || echo "No report files found in root"
          ls -la report* 2>/dev/null || echo "No report files found"
          # ZAP baseline creates report_json.json, we need to check for sarif
          if [ -f "report_json.json" ]; then
            echo "Found report_json.json"
            cat report_json.json | head -50
          fi
        continue-on-error: true

      # Convert ZAP JSON to SARIF format
      - name: Convert ZAP JSON to SARIF
        run: |
          if [ -f "report_json.json" ]; then
            echo "Converting ZAP JSON to SARIF format..."
            python3 << 'EOF'
          import json
          import re
          import subprocess
          from urllib.parse import urlparse

          with open('report_json.json', 'r') as f:
              zap = json.load(f)

          # Build a map of URL paths to line numbers by scanning server.js
          # This makes the solution work for any repo - just scan for route definitions
          path_to_line = {'/': 1}  # default
          try:
              with open('server.js', 'r') as f:
                  for line_num, line in enumerate(f, 1):
                      # Match Express routes: app.get('/path', ...) or app.post('/path', ...)
                      match = re.search(r"app\.(get|post|put|delete|all)\s*\(\s*['\"]([^'\"]+)['\"]", line)
                      if match:
                          path_to_line[match.group(2)] = line_num
          except FileNotFoundError:
              pass

          sarif = {
              "$schema": "https://json.schemastore.org/sarif-2.1.0.json",
              "version": "2.1.0",
              "runs": [{
                  "tool": {
                      "driver": {
                          "name": "OWASP ZAP",
                          "semanticVersion": zap.get("@version", "2.16.0"),
                          "informationUri": "https://www.zaproxy.org/",
                          "rules": []
                      }
                  },
                  "results": []
              }]
          }

          rules = {}
          results = []
          rule_index_map = {}

          risk_to_level = {"0": "note", "1": "note", "2": "warning", "3": "error"}
          risk_to_severity = {"0": "1.0", "1": "3.0", "2": "6.0", "3": "9.0"}

          def extract_url(text):
              """Extract clean URL from ZAP's HTML-wrapped reference field"""
              if not text:
                  return None
              urls = re.findall(r'https?://[^\s<>"]+', text)
              for url in urls:
                  if url.startswith('http'):
                      return url.rstrip('.,;:')
              return None

          def clean_html(text):
              """Remove HTML tags from text"""
              if not text:
                  return ""
              return re.sub(r'<[^>]+>', '', text).strip()

          def get_line_for_path(url_path):
              """Find the line number for a URL path"""
              # Exact match first
              if url_path in path_to_line:
                  return path_to_line[url_path]
              # Try without query string
              clean_path = url_path.split('?')[0]
              if clean_path in path_to_line:
                  return path_to_line[clean_path]
              # Try base path for api routes like /api/products -> /api
              for known_path in sorted(path_to_line.keys(), key=len, reverse=True):
                  if clean_path.startswith(known_path) and known_path != '/':
                      return path_to_line[known_path]
              return path_to_line.get('/', 1)

          for site in zap.get("site", []):
              for alert in site.get("alerts", []):
                  rule_id = f"zap-{alert.get('pluginid', 'unknown')}"
                  alert_name = alert.get("name", "Unknown")
                  
                  if rule_id not in rules:
                      help_uri = extract_url(alert.get("reference", ""))
                      
                      rule = {
                          "id": rule_id,
                          "name": alert_name.replace(" ", "")[:512],
                          "shortDescription": {"text": alert_name[:1024]},
                          "fullDescription": {"text": clean_html(alert.get("desc", "Security issue detected"))[:1024]},
                          "help": {
                              "text": clean_html(alert.get("solution", "Review and fix this security issue.")),
                              "markdown": f"**{alert_name}**\n\n{clean_html(alert.get('solution', ''))}"
                          },
                          "properties": {
                              "security-severity": risk_to_severity.get(alert.get("riskcode", "1"), "5.0"),
                              "tags": ["security", "zap"]
                          }
                      }
                      if help_uri:
                          rule["helpUri"] = help_uri
                      
                      rule_index_map[rule_id] = len(rules)
                      rules[rule_id] = rule
                  
                  for instance in alert.get("instances", []):
                      uri = instance.get("uri", "")
                      method = instance.get("method", "GET")
                      param = instance.get("param", "")
                      
                      # Parse URL to get path
                      parsed = urlparse(uri)
                      url_path = parsed.path if parsed.path else "/"
                      line_num = get_line_for_path(url_path)
                      
                      message_text = f"{alert_name}"
                      if param:
                          message_text += f" in parameter '{param}'"
                      message_text += f" [{method} {url_path}]"
                      
                      # DO NOT include partialFingerprints - let GitHub calculate them
                      # GitHub uses file+line to create stable fingerprints
                      results.append({
                          "ruleId": rule_id,
                          "ruleIndex": rule_index_map[rule_id],
                          "level": risk_to_level.get(alert.get("riskcode", "1"), "warning"),
                          "message": {"text": message_text[:1024]},
                          "locations": [{
                              "physicalLocation": {
                                  "artifactLocation": {"uri": "server.js"},
                                  "region": {
                                      "startLine": line_num,
                                      "startColumn": 1
                                  }
                              }
                          }]
                      })

          sarif["runs"][0]["tool"]["driver"]["rules"] = list(rules.values())
          sarif["runs"][0]["results"] = results

          with open('zap-results.sarif', 'w') as f:
              json.dump(sarif, f, indent=2)
          print(f"Created zap-results.sarif with {len(results)} findings and {len(rules)} rules")
          print(f"Path to line mappings: {len(path_to_line)} routes found")
          EOF
          fi
        continue-on-error: true

      - name: Upload ZAP SARIF Report
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: 'zap-results.sarif'
          category: 'zap-scan'
        if: hashFiles('zap-results.sarif') != ''
        continue-on-error: true

      # Nuclei Scan - outputs SARIF format
      - name: Nuclei Scan
        uses: projectdiscovery/nuclei-action@v2.0.2
        with:
          target: 'http://${{ steps.ip.outputs.address }}:3000'
          sarif-export: 'nuclei-results.sarif'
          flags: '-severity critical,high,medium,low,info -rate-limit 150'
          github-token: ${{ secrets.GITHUB_TOKEN }}
        continue-on-error: true

      - name: Check Nuclei outputs
        run: |
          echo "=== Checking for Nuclei output files ==="
          ls -la *.sarif 2>/dev/null || echo "No SARIF files found"
          ls -la nuclei* 2>/dev/null || echo "No nuclei files found"
          if [ -f "nuclei-results.sarif" ]; then
            echo "Found nuclei-results.sarif"
            cat nuclei-results.sarif | head -50
          fi
        continue-on-error: true

      # Fix SARIF files for GitHub Code Scanning
      # GitHub calculates fingerprints from file+line - don't provide our own
      - name: Fix SARIF files for GitHub
        run: |
          if [ -f "nuclei-results.sarif" ]; then
            echo "Creating GitHub-compatible SARIF from Nuclei results..."
            python3 << 'EOF'
          import json
          import re
          from urllib.parse import urlparse

          with open('nuclei-results.sarif', 'r') as f:
              original = json.load(f)

          # Build a map of URL paths to line numbers by scanning server.js
          # This makes the solution portable to any repo
          path_to_line = {'/': 1}
          try:
              with open('server.js', 'r') as f:
                  for line_num, line in enumerate(f, 1):
                      match = re.search(r"app\.(get|post|put|delete|all)\s*\(\s*['\"]([^'\"]+)['\"]", line)
                      if match:
                          path_to_line[match.group(2)] = line_num
          except FileNotFoundError:
              pass

          def get_line_for_path(url_path):
              """Find the line number for a URL path"""
              if url_path in path_to_line:
                  return path_to_line[url_path]
              clean_path = url_path.split('?')[0]
              if clean_path in path_to_line:
                  return path_to_line[clean_path]
              for known_path in sorted(path_to_line.keys(), key=len, reverse=True):
                  if clean_path.startswith(known_path) and known_path != '/':
                      return path_to_line[known_path]
              return path_to_line.get('/', 1)

          def extract_path_from_message(message):
              """Extract URL path from Nuclei finding message"""
              # Try to find URL in message
              match = re.search(r'https?://[^/]+(/[^\s\]"]*)', message)
              if match:
                  return match.group(1)
              # Try to find path in square brackets [path=/xxx]
              match = re.search(r'\[paths?="?(/[^"\]\s]+)"?\]', message)
              if match:
                  return match.group(1)
              match = re.search(r'\[path="?(/[^"\]\s]+)"?\]', message)
              if match:
                  return match.group(1)
              return '/'

          new_sarif = {
              "$schema": "https://json.schemastore.org/sarif-2.1.0.json",
              "version": "2.1.0",
              "runs": []
          }

          for run in original.get('runs', []):
              tool = run.get('tool', {}).get('driver', {})
              
              new_run = {
                  "tool": {
                      "driver": {
                          "name": tool.get('name', 'Nuclei'),
                          "semanticVersion": tool.get('semanticVersion', '3.0.0').lstrip('v'),
                          "informationUri": "https://github.com/projectdiscovery/nuclei",
                          "rules": []
                      }
                  },
                  "results": []
              }
              
              rules_map = {}
              for rule in tool.get('rules', []):
                  rule_id = rule.get('id', 'unknown')
                  short_desc = rule.get('shortDescription', {}).get('text', rule_id)
                  full_desc = rule.get('fullDescription', {}).get('text', 'Security finding')
                  
                  new_rule = {
                      "id": rule_id,
                      "name": rule_id.replace("-", "").replace(":", "").title()[:512],
                      "shortDescription": {"text": short_desc[:1024]},
                      "fullDescription": {"text": full_desc[:1024] if full_desc else "Security finding detected"},
                      "help": {
                          "text": f"Security vulnerability detected: {short_desc}",
                          "markdown": f"**{short_desc}**\n\nDetected by Nuclei vulnerability scanner."
                      },
                      "properties": {
                          "security-severity": str(rule.get('properties', {}).get('security-severity', '5.0')),
                          "tags": ["security", "nuclei"]
                      }
                  }
                  rules_map[rule_id] = len(new_run["tool"]["driver"]["rules"])
                  new_run["tool"]["driver"]["rules"].append(new_rule)
              
              for result in run.get('results', []):
                  rule_id = result.get('ruleId', 'unknown')
                  message = result.get('message', {}).get('text', 'Security finding')
                  
                  # Extract URL path from message and map to line number
                  url_path = extract_path_from_message(message)
                  line_num = get_line_for_path(url_path)
                  
                  # DO NOT include partialFingerprints - let GitHub calculate them
                  new_result = {
                      "ruleId": rule_id,
                      "ruleIndex": rules_map.get(rule_id, 0),
                      "level": "warning",
                      "message": {"text": message[:1024]},
                      "locations": [{
                          "physicalLocation": {
                              "artifactLocation": {"uri": "server.js"},
                              "region": {
                                  "startLine": line_num,
                                  "startColumn": 1
                              }
                          }
                      }]
                  }
                  new_run["results"].append(new_result)
              
              new_sarif["runs"].append(new_run)

          with open('nuclei-results-fixed.sarif', 'w') as f:
              json.dump(new_sarif, f, indent=2)
          
          print(f"Created nuclei-results-fixed.sarif with {len(new_sarif['runs'][0]['results'])} findings")
          print(f"Path to line mappings: {len(path_to_line)} routes found")
          EOF
          fi
        continue-on-error: true

      - name: Upload Nuclei SARIF Report
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: 'nuclei-results-fixed.sarif'
          category: 'nuclei-scan'
        if: hashFiles('nuclei-results-fixed.sarif') != ''
        continue-on-error: true

      # Save reports as artifacts
      - name: Upload Reports as Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: security-scan-reports
          path: |
            *.sarif
            *.json
            *.html
            *.md
          retention-days: 30
        if: always()

name: Security Scan (ZAP + Nuclei)

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:

permissions:
  contents: read
  security-events: write

jobs:
  build-and-scan:
    name: Build and Security Scan
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # Build and start the application
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Start application in background
        run: npm start &
        env:
          PORT: 3000

      - name: Wait for application to be ready
        run: |
          echo "Waiting for application to start..."
          timeout 60 bash -c 'until curl -sf http://localhost:3000/health > /dev/null 2>&1; do sleep 2; done'
          echo "Application is ready!"

      - name: Get runner IP for Docker access
        id: ip
        run: echo "address=$(hostname -I | awk '{print $1}')" >> $GITHUB_OUTPUT

      # ZAP Scan - outputs SARIF format
      - name: ZAP Baseline Scan
        uses: zaproxy/action-baseline@v0.14.0
        with:
          target: 'http://${{ steps.ip.outputs.address }}:3000'
          cmd_options: '-a'
          fail_action: false
          allow_issue_writing: false
        continue-on-error: true

      # Convert ZAP JSON to SARIF if needed
      - name: Check ZAP outputs
        run: |
          echo "=== Checking for ZAP output files ==="
          ls -la *.json *.sarif *.html *.md 2>/dev/null || echo "No report files found in root"
          ls -la report* 2>/dev/null || echo "No report files found"
          # ZAP baseline creates report_json.json, we need to check for sarif
          if [ -f "report_json.json" ]; then
            echo "Found report_json.json"
            cat report_json.json | head -50
          fi
        continue-on-error: true

      # Convert ZAP JSON to SARIF format
      - name: Convert ZAP JSON to SARIF
        run: |
          if [ -f "report_json.json" ]; then
            echo "Converting ZAP JSON to SARIF format..."
            python3 << 'EOF'
          import json

          with open('report_json.json', 'r') as f:
              zap = json.load(f)

          sarif = {
              "version": "2.1.0",
              "$schema": "https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json",
              "runs": [{
                  "tool": {
                      "driver": {
                          "name": "OWASP ZAP",
                          "version": zap.get("@version", "unknown"),
                          "informationUri": "https://www.zaproxy.org/",
                          "rules": []
                      }
                  },
                  "results": []
              }]
          }

          rules = {}
          results = []

          risk_to_level = {"0": "note", "1": "note", "2": "warning", "3": "error"}
          risk_to_severity = {"0": "1", "1": "3", "2": "6", "3": "9"}

          for site in zap.get("site", []):
              for alert in site.get("alerts", []):
                  rule_id = alert.get("pluginid", "unknown")
                  
                  if rule_id not in rules:
                      rules[rule_id] = {
                          "id": rule_id,
                          "name": alert.get("name", "Unknown"),
                          "shortDescription": {"text": alert.get("name", "Unknown")},
                          "fullDescription": {"text": alert.get("desc", "")[:1000]},
                          "helpUri": alert.get("reference", "").split("\n")[0] if alert.get("reference") else "",
                          "properties": {
                              "security-severity": risk_to_severity.get(alert.get("riskcode", "1"), "5")
                          }
                      }
                  
                  for instance in alert.get("instances", []):
                      uri = instance.get("uri", "")
                      # Convert URL to file-like path
                      from urllib.parse import urlparse
                      parsed = urlparse(uri)
                      path = parsed.path if parsed.path and parsed.path != '/' else '/index'
                      
                      results.append({
                          "ruleId": rule_id,
                          "level": risk_to_level.get(alert.get("riskcode", "1"), "warning"),
                          "message": {
                              "text": f"{alert.get('name', 'Unknown')}: {alert.get('solution', '')[:500]}"
                          },
                          "locations": [{
                              "physicalLocation": {
                                  "artifactLocation": {
                                      "uri": f"web{path}",
                                      "uriBaseId": "%SRCROOT%"
                                  },
                                  "region": {"startLine": 1, "startColumn": 1}
                              }
                          }]
                      })

          sarif["runs"][0]["tool"]["driver"]["rules"] = list(rules.values())
          sarif["runs"][0]["results"] = results

          with open('zap-results.sarif', 'w') as f:
              json.dump(sarif, f, indent=2)
          print(f"Created zap-results.sarif with {len(results)} findings")
          EOF
          fi
        continue-on-error: true

      - name: Upload ZAP SARIF Report
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'zap-results.sarif'
          category: 'zap-scan'
        if: hashFiles('zap-results.sarif') != ''
        continue-on-error: true

      # Nuclei Scan - outputs SARIF format
      - name: Nuclei Scan
        uses: projectdiscovery/nuclei-action@v2.0.1
        with:
          target: 'http://${{ steps.ip.outputs.address }}:3000'
          sarif-export: 'nuclei-results.sarif'
          severity: 'critical,high,medium,low,info'
          rate-limit: 150
          github-token: ${{ secrets.GITHUB_TOKEN }}
        continue-on-error: true

      - name: Check Nuclei outputs
        run: |
          echo "=== Checking for Nuclei output files ==="
          ls -la *.sarif 2>/dev/null || echo "No SARIF files found"
          ls -la nuclei* 2>/dev/null || echo "No nuclei files found"
          if [ -f "nuclei-results.sarif" ]; then
            echo "Found nuclei-results.sarif"
            cat nuclei-results.sarif | head -50
          fi
        continue-on-error: true

      # Fix SARIF files for GitHub Code Scanning
      # GitHub requires file paths, not URLs, in the location field
      - name: Fix SARIF files for GitHub
        run: |
          # Debug: Show original Nuclei SARIF structure
          if [ -f "nuclei-results.sarif" ]; then
            echo "=== Original Nuclei SARIF structure ==="
            python3 -c "
          import json
          with open('nuclei-results.sarif') as f:
              d = json.load(f)
          for run in d.get('runs', []):
              for r in run.get('results', [])[:2]:
                  print('Result:', json.dumps(r, indent=2)[:1000])
          "
          fi
          
          # Create a completely new SARIF file from Nuclei results
          if [ -f "nuclei-results.sarif" ]; then
            echo "Creating new GitHub-compatible SARIF from Nuclei results..."
            python3 << 'EOF'
          import json
          from urllib.parse import urlparse

          with open('nuclei-results.sarif', 'r') as f:
              original = json.load(f)

          # Build a new SARIF from scratch
          new_sarif = {
              "version": "2.1.0",
              "$schema": "https://json.schemastore.org/sarif-2.1.0.json",
              "runs": []
          }

          for run in original.get('runs', []):
              tool = run.get('tool', {}).get('driver', {})
              
              new_run = {
                  "tool": {
                      "driver": {
                          "name": tool.get('name', 'Nuclei'),
                          "version": tool.get('semanticVersion', 'unknown'),
                          "informationUri": "https://github.com/projectdiscovery/nuclei",
                          "rules": []
                      }
                  },
                  "results": []
              }
              
              # Process rules
              rules_map = {}
              for rule in tool.get('rules', []):
                  rule_id = rule.get('id', 'unknown')
                  severity = rule.get('properties', {}).get('security-severity', '5')
                  new_rule = {
                      "id": rule_id,
                      "name": rule.get('name', rule_id),
                      "shortDescription": {"text": rule.get('shortDescription', {}).get('text', rule_id)},
                      "fullDescription": {"text": rule.get('fullDescription', {}).get('text', '')[:500]},
                      "defaultConfiguration": {"level": "warning"},
                      "properties": {"security-severity": str(severity)}
                  }
                  rules_map[rule_id] = new_rule
                  new_run["tool"]["driver"]["rules"].append(new_rule)
              
              # Process results
              for result in run.get('results', []):
                  rule_id = result.get('ruleId', 'unknown')
                  message = result.get('message', {}).get('text', 'Security finding')
                  
                  # Extract URL and convert to file path
                  file_path = "web/index.html"  # default
                  for loc in result.get('locations', []):
                      phys = loc.get('physicalLocation', {})
                      artifact = phys.get('artifactLocation', {})
                      uri = artifact.get('uri', '')
                      
                      if uri:
                          # Parse URL and extract path
                          if uri.startswith('http'):
                              parsed = urlparse(uri)
                              path = parsed.path.strip('/')
                              if path:
                                  file_path = f"web/{path}"
                              else:
                                  file_path = "web/index.html"
                          else:
                              file_path = uri if not uri.startswith('/') else uri[1:]
                  
                  # Ensure file_path is valid
                  if not file_path or file_path == "web/":
                      file_path = "web/index.html"
                  
                  new_result = {
                      "ruleId": rule_id,
                      "level": "warning",
                      "message": {"text": message[:500]},
                      "locations": [
                          {
                              "physicalLocation": {
                                  "artifactLocation": {
                                      "uri": file_path
                                  },
                                  "region": {
                                      "startLine": 1,
                                      "startColumn": 1,
                                      "endLine": 1,
                                      "endColumn": 1
                                  }
                              }
                          }
                      ]
                  }
                  new_run["results"].append(new_result)
              
              new_sarif["runs"].append(new_run)

          with open('nuclei-results-fixed.sarif', 'w') as f:
              json.dump(new_sarif, f, indent=2)
          
          print(f"Created nuclei-results-fixed.sarif with {len(new_sarif['runs'][0]['results'])} findings")
          
          # Debug output
          print("\n=== Sample converted result ===")
          if new_sarif['runs'] and new_sarif['runs'][0]['results']:
              print(json.dumps(new_sarif['runs'][0]['results'][0], indent=2))
          EOF
          fi

          # Ensure all referenced files exist in the repo
          mkdir -p web/.git
          for f in index.html .env config.json backup.sql swagger.json graphql .git/config wp-config.php.bak logs/access.log; do
            dir="web/$(dirname $f)"
            mkdir -p "$dir" 2>/dev/null || true
            echo "# Placeholder for security scan" > "web/$f"
          done
          
          echo "=== Created placeholder files ==="
          find web -type f | head -20
        continue-on-error: true

      - name: Upload Nuclei SARIF Report
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'nuclei-results-fixed.sarif'
          category: 'nuclei-scan'
        if: hashFiles('nuclei-results-fixed.sarif') != ''
        continue-on-error: true

      # Save reports as artifacts
      - name: Upload Reports as Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: security-scan-reports
          path: |
            *.sarif
            *.json
            *.html
            *.md
          retention-days: 30
        if: always()
